{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict \n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "import re\n",
    "import unicodedata\n",
    "from nlp_preprocessing import *\n",
    "from topic_modeling import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS, CountVectorizer\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# pd.reset_option('display.max_colwidth')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>global_bias</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>news_title</th>\n",
       "      <th>news_source</th>\n",
       "      <th>news_link</th>\n",
       "      <th>bias</th>\n",
       "      <th>paras</th>\n",
       "      <th>authors</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>From the Left</td>\n",
       "      <td>Trump Administration Drops Citizenship Question From Census</td>\n",
       "      <td>July 3rd, 2019</td>\n",
       "      <td>['The Trump Administration dropped plans to add a citizenship question to the 2020 census, after...</td>\n",
       "      <td>https://www.allsides.com/story/trump-administration-drops-citizenship-question-census</td>\n",
       "      <td>Trump Responds After His Administration Drops Bid For Citizenship Question On 2020 Census</td>\n",
       "      <td>HuffPost</td>\n",
       "      <td>https://www.huffpost.com/entry/trump-citizenship-question-2020-census_n_5d1bd769e4b082e553718d6b</td>\n",
       "      <td>Left</td>\n",
       "      <td>President Donald Trump spoke out Tuesday on his administration’s decision not to add a citizensh...</td>\n",
       "      <td>['Antonia Blumberg', 'Huffpost Us', 'Reporter']</td>\n",
       "      <td>2019-07-03 08:13:05+05:30</td>\n",
       "      <td>“A very sad time for America when the Supreme Court of the United States won’t allow a question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>From the Right</td>\n",
       "      <td>Trump Administration Drops Citizenship Question From Census</td>\n",
       "      <td>July 3rd, 2019</td>\n",
       "      <td>['The Trump Administration dropped plans to add a citizenship question to the 2020 census, after...</td>\n",
       "      <td>https://www.allsides.com/story/trump-administration-drops-citizenship-question-census</td>\n",
       "      <td>Trump administration drops push for citizenship question on 2020 census</td>\n",
       "      <td>Washington Times</td>\n",
       "      <td>https://www.washingtontimes.com/news/2019/jul/2/trump-drops-push-citizenship-question-2020-census/</td>\n",
       "      <td>Lean Right</td>\n",
       "      <td>President Trump’s quest to add a citizenship question to the 2020 census ended Tuesday, with the...</td>\n",
       "      <td>['The Washington Times Http', 'Stephen Dinan']</td>\n",
       "      <td>2019-07-02 00:00:00</td>\n",
       "      <td>President Trump‘s quest to add a citizenship question to the 2020 census ended Tuesday, with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>From the Left</td>\n",
       "      <td>Iran to Surpass Uranium Enrichment Breaching Nuclear Agreement</td>\n",
       "      <td>July 7th, 2019</td>\n",
       "      <td>['On Sunday, Iranian officials said the country will exceed the limits set in the 2015 nuclear d...</td>\n",
       "      <td>https://www.allsides.com/story/iran-surpass-uranium-enrichment-breaching-nuclear-agreement</td>\n",
       "      <td>Iran Announces New Breach of Nuclear Deal Limits, and Threatens Further Violations</td>\n",
       "      <td>New York Times (News)</td>\n",
       "      <td>https://www.nytimes.com/2019/07/07/world/middleeast/iran-nuclear-limits-breach.html</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Iran said on Sunday that within hours it would breach the limits on uranium enrichment set four ...</td>\n",
       "      <td>['David D. Kirkpatrick', 'David E. Sanger']</td>\n",
       "      <td>2019-07-07 00:00:00</td>\n",
       "      <td>Iran said on Sunday that within hours it would breach the limits on uranium enrichment set four ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>From the Right</td>\n",
       "      <td>Iran to Surpass Uranium Enrichment Breaching Nuclear Agreement</td>\n",
       "      <td>July 7th, 2019</td>\n",
       "      <td>['On Sunday, Iranian officials said the country will exceed the limits set in the 2015 nuclear d...</td>\n",
       "      <td>https://www.allsides.com/story/iran-surpass-uranium-enrichment-breaching-nuclear-agreement</td>\n",
       "      <td>Iran raises uranium enrichment as nuclear deal unravels</td>\n",
       "      <td>Washington Times</td>\n",
       "      <td>https://www.washingtontimes.com/news/2019/jul/7/iran-raises-uranium-enrichment-nuclear-deal-unrave/</td>\n",
       "      <td>Lean Right</td>\n",
       "      <td>Iran announced Sunday it will raise its level of uranium enrichment, breaking another limit of i...</td>\n",
       "      <td>['The Washington Times Http', 'Jon Gambrell', 'Nasser Karimi']</td>\n",
       "      <td>2019-07-07 00:00:00</td>\n",
       "      <td>TEHRAN, Iran — Iran announced Sunday it will raise its level of uranium enrichment, breaking ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>From the Left</td>\n",
       "      <td>Social Media Summit Draws Wide Range of Coverage</td>\n",
       "      <td>July 12th, 2019</td>\n",
       "      <td>[\"The 'Social Media Summit' hosted by President Donald Trump at the White House on Thursday made...</td>\n",
       "      <td>https://www.allsides.com/story/social-media-summit-draws-wide-range-coverage</td>\n",
       "      <td>Trump accuses social media companies of ‘terrible bias’ at White House summit decried by critics</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>https://www.washingtonpost.com/technology/2019/07/11/we-will-not-let-them-get-away-with-it-trump...</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>President Trump assailed Facebook, Google and Twitter on Thursday — accusing them of exhibiting ...</td>\n",
       "      <td>['Tony Romm', 'Senior Tech Policy Reporter']</td>\n",
       "      <td>2019-07-11 00:00:00</td>\n",
       "      <td>“Some of you are extraordinary. The crap you think of is unbelievable,” Trump said.\\n\\nAD\\n\\nTru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number     global_bias  \\\n",
       "0       5   From the Left   \n",
       "1       5  From the Right   \n",
       "2      15   From the Left   \n",
       "3      15  From the Right   \n",
       "4      25   From the Left   \n",
       "\n",
       "                                                            title  \\\n",
       "0     Trump Administration Drops Citizenship Question From Census   \n",
       "1     Trump Administration Drops Citizenship Question From Census   \n",
       "2  Iran to Surpass Uranium Enrichment Breaching Nuclear Agreement   \n",
       "3  Iran to Surpass Uranium Enrichment Breaching Nuclear Agreement   \n",
       "4                Social Media Summit Draws Wide Range of Coverage   \n",
       "\n",
       "              date  \\\n",
       "0   July 3rd, 2019   \n",
       "1   July 3rd, 2019   \n",
       "2   July 7th, 2019   \n",
       "3   July 7th, 2019   \n",
       "4  July 12th, 2019   \n",
       "\n",
       "                                                                                               summary  \\\n",
       "0  ['The Trump Administration dropped plans to add a citizenship question to the 2020 census, after...   \n",
       "1  ['The Trump Administration dropped plans to add a citizenship question to the 2020 census, after...   \n",
       "2  ['On Sunday, Iranian officials said the country will exceed the limits set in the 2015 nuclear d...   \n",
       "3  ['On Sunday, Iranian officials said the country will exceed the limits set in the 2015 nuclear d...   \n",
       "4  [\"The 'Social Media Summit' hosted by President Donald Trump at the White House on Thursday made...   \n",
       "\n",
       "                                                                                         link  \\\n",
       "0       https://www.allsides.com/story/trump-administration-drops-citizenship-question-census   \n",
       "1       https://www.allsides.com/story/trump-administration-drops-citizenship-question-census   \n",
       "2  https://www.allsides.com/story/iran-surpass-uranium-enrichment-breaching-nuclear-agreement   \n",
       "3  https://www.allsides.com/story/iran-surpass-uranium-enrichment-breaching-nuclear-agreement   \n",
       "4                https://www.allsides.com/story/social-media-summit-draws-wide-range-coverage   \n",
       "\n",
       "                                                                                         news_title  \\\n",
       "0         Trump Responds After His Administration Drops Bid For Citizenship Question On 2020 Census   \n",
       "1                           Trump administration drops push for citizenship question on 2020 census   \n",
       "2                Iran Announces New Breach of Nuclear Deal Limits, and Threatens Further Violations   \n",
       "3                                           Iran raises uranium enrichment as nuclear deal unravels   \n",
       "4  Trump accuses social media companies of ‘terrible bias’ at White House summit decried by critics   \n",
       "\n",
       "             news_source  \\\n",
       "0               HuffPost   \n",
       "1       Washington Times   \n",
       "2  New York Times (News)   \n",
       "3       Washington Times   \n",
       "4        Washington Post   \n",
       "\n",
       "                                                                                             news_link  \\\n",
       "0     https://www.huffpost.com/entry/trump-citizenship-question-2020-census_n_5d1bd769e4b082e553718d6b   \n",
       "1   https://www.washingtontimes.com/news/2019/jul/2/trump-drops-push-citizenship-question-2020-census/   \n",
       "2                  https://www.nytimes.com/2019/07/07/world/middleeast/iran-nuclear-limits-breach.html   \n",
       "3  https://www.washingtontimes.com/news/2019/jul/7/iran-raises-uranium-enrichment-nuclear-deal-unrave/   \n",
       "4  https://www.washingtonpost.com/technology/2019/07/11/we-will-not-let-them-get-away-with-it-trump...   \n",
       "\n",
       "         bias  \\\n",
       "0        Left   \n",
       "1  Lean Right   \n",
       "2   Lean Left   \n",
       "3  Lean Right   \n",
       "4   Lean Left   \n",
       "\n",
       "                                                                                                 paras  \\\n",
       "0  President Donald Trump spoke out Tuesday on his administration’s decision not to add a citizensh...   \n",
       "1  President Trump’s quest to add a citizenship question to the 2020 census ended Tuesday, with the...   \n",
       "2  Iran said on Sunday that within hours it would breach the limits on uranium enrichment set four ...   \n",
       "3  Iran announced Sunday it will raise its level of uranium enrichment, breaking another limit of i...   \n",
       "4  President Trump assailed Facebook, Google and Twitter on Thursday — accusing them of exhibiting ...   \n",
       "\n",
       "                                                          authors  \\\n",
       "0                 ['Antonia Blumberg', 'Huffpost Us', 'Reporter']   \n",
       "1                  ['The Washington Times Http', 'Stephen Dinan']   \n",
       "2                     ['David D. Kirkpatrick', 'David E. Sanger']   \n",
       "3  ['The Washington Times Http', 'Jon Gambrell', 'Nasser Karimi']   \n",
       "4                    ['Tony Romm', 'Senior Tech Policy Reporter']   \n",
       "\n",
       "                publish_date  \\\n",
       "0  2019-07-03 08:13:05+05:30   \n",
       "1        2019-07-02 00:00:00   \n",
       "2        2019-07-07 00:00:00   \n",
       "3        2019-07-07 00:00:00   \n",
       "4        2019-07-11 00:00:00   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  “A very sad time for America when the Supreme Court of the United States won’t allow a question ...  \n",
       "1  President Trump‘s quest to add a citizenship question to the 2020 census ended Tuesday, with the...  \n",
       "2  Iran said on Sunday that within hours it would breach the limits on uranium enrichment set four ...  \n",
       "3  TEHRAN, Iran — Iran announced Sunday it will raise its level of uranium enrichment, breaking ano...  \n",
       "4  “Some of you are extraordinary. The crap you think of is unbelievable,” Trump said.\\n\\nAD\\n\\nTru...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_round1 = pd.read_csv(\"../Data/data_NLP_round1.csv\")\n",
    "\n",
    "df_nlp_round1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each news article can contain slightly different unicode formatting, its best to convert everything to ascii format, to make it easier to work the data. All incomptabile characters will be converted or dropped. Since we are working with English, the hope is that a majority of the data is retained.\n",
    "**But we can come to this later to see how much data is being dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_ascii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>OTTAWA — The security fences are coming down. And the world leaders have jetted off.\\n\\nBut for ...</td>\n",
       "      <td>OTTAWA  The security fences are coming down. And the world leaders have jetted off.\\n\\nBut for P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    text  \\\n",
       "830  OTTAWA — The security fences are coming down. And the world leaders have jetted off.\\n\\nBut for ...   \n",
       "\n",
       "                                                                                              text_ascii  \n",
       "830  OTTAWA  The security fences are coming down. And the world leaders have jetted off.\\n\\nBut for P...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensuring everything is in ascii format and removing any wierd formatings.\n",
    "df_nlp_round1['text_ascii'] = df_nlp_round1.text.map(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('ascii'))\n",
    "df_nlp_round1[['text','text_ascii']].sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Into Paras\n",
    "\n",
    "Let's breakout each news article into paragraphs and expand this into a new dataframe.  \n",
    "These paragraphs will be treated as individual documents that will be used to vectorize & topic model. Post which, for a given overall news headline, each paragraph from the left & right bias will be compared to see pair up paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded = df_nlp_round1[['number','global_bias','title','news_source','text_ascii']].copy(deep=True)\n",
    "\n",
    "# Splitting each para into a list of paras\n",
    "df_expanded['text_paras_list'] = df_expanded.text_ascii.str.split('\\n\\n')\n",
    "\n",
    "# Exploding the paragraphs into a dataframe, where each row has a paragraph\n",
    "df_expanded_col = pd.DataFrame(df_expanded.text_paras_list.explode())\n",
    "df_expanded_col.rename(columns={'text_paras_list':'text_paras'}, inplace=True)\n",
    "\n",
    "# Joining the exploded dataframe back, so that other metadata can be associated with it\n",
    "df_expanded = df_expanded.join(df_expanded_col,).reset_index()\n",
    "df_expanded.rename(columns={'index':'article'}, inplace=True)\n",
    "df_expanded.drop(columns='text_paras_list', inplace=True)\n",
    "\n",
    "# getting paragraph numbering\n",
    "df_expanded['para_count'] = df_expanded.groupby('article').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_paras</th>\n",
       "      <th>text_paras_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9657</th>\n",
       "      <td>But the president is expected to focus on economic fairness issues, such as the minimum wage, as part of his push to reverse increasing income disparity in America, which he calls the defining issue of our time.</td>\n",
       "      <td>but the president is expected to focus on economic fairness issues  such as the minimum wage  as part of his push to reverse increasing income disparity in america  which he calls the defining issue of our time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15161</th>\n",
       "      <td>AD</td>\n",
       "      <td>ad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                text_paras  \\\n",
       "9657   But the president is expected to focus on economic fairness issues, such as the minimum wage, as part of his push to reverse increasing income disparity in America, which he calls the defining issue of our time.   \n",
       "15161                                                                                                                                                                                                                   AD   \n",
       "\n",
       "                                                                                                                                                                                                          text_paras_clean  \n",
       "9657   but the president is expected to focus on economic fairness issues  such as the minimum wage  as part of his push to reverse increasing income disparity in america  which he calls the defining issue of our time   \n",
       "15161                                                                                                                                                                                                                   ad  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expanded['text_paras_clean'] = df_expanded.text_paras.map(cleaning)\n",
    "df_expanded[['text_paras','text_paras_clean']].sample(2)\n",
    "\n",
    "# df_nlp_round1['text_clean'] = df_nlp_round1.text_ascii.map(cleaning)\n",
    "# df_nlp_round1[['text','text_clean']].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_paras_clean</th>\n",
       "      <th>text_paras_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22327</th>\n",
       "      <td>if not him  then mr  mccabe or other f b i  officials interviewing with mr  trump for the job could perhaps wear a wire or otherwise record the president  mr  rosenstein offered  white house officials never checked his phone when he arrived for meetings there  mr  rosenstein added  implying it would be easy to secretly record mr  trump</td>\n",
       "      <td>if not    then mr   mccabe or other f b i   official interview with mr   trump for the job could perhaps wear a wire or otherwise record the president   mr   rosenstein offer   white house official never check  phone when  arrive for meeting there   mr   rosenstein add   imply  would be easy to secretly record mr   trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>to win big on family feud two members of a family have to combine to get 200 points  so when tim sass scored an epic 182 points in the final round of his familys appearance on the long running game show  he must have felt pretty confident that his team would walk away with $20 000  but he didnt remember the political adage  you are never as far up as you think you are  when his relative anna stepped up to the plate  she got exactly zero points   for example  no one in the survey though that throw up was a good answer for something a stomach did  the sass family did walk away with $5 per point and $910 aint too shabby</td>\n",
       "      <td>to win big on family feud two member of a family have to combine to get 200 point   so when tim sass score an epic 182 point in the final round of  familys appearance on the long running game show    must have feel pretty confident that  team would walk away with $ 20 000   but  do not remember the political adage    be never as far up as  think  be   when  relative anna step up to the plate    get exactly zero point    for example   no one in the survey though that throw up be a good answer for something a stomach do   the sass family do walk away with $ 5 per point and $ 910 be not too shabby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text_paras_clean  \\\n",
       "22327                                                                                                                                                                                                                                                                                                 if not him  then mr  mccabe or other f b i  officials interviewing with mr  trump for the job could perhaps wear a wire or otherwise record the president  mr  rosenstein offered  white house officials never checked his phone when he arrived for meetings there  mr  rosenstein added  implying it would be easy to secretly record mr  trump    \n",
       "10107  to win big on family feud two members of a family have to combine to get 200 points  so when tim sass scored an epic 182 points in the final round of his familys appearance on the long running game show  he must have felt pretty confident that his team would walk away with $20 000  but he didnt remember the political adage  you are never as far up as you think you are  when his relative anna stepped up to the plate  she got exactly zero points   for example  no one in the survey though that throw up was a good answer for something a stomach did  the sass family did walk away with $5 per point and $910 aint too shabby    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text_paras_lemma  \n",
       "22327                                                                                                                                                                                                                                                                                         if not    then mr   mccabe or other f b i   official interview with mr   trump for the job could perhaps wear a wire or otherwise record the president   mr   rosenstein offer   white house official never check  phone when  arrive for meeting there   mr   rosenstein add   imply  would be easy to secretly record mr   trump  \n",
       "10107  to win big on family feud two member of a family have to combine to get 200 point   so when tim sass score an epic 182 point in the final round of  familys appearance on the long running game show    must have feel pretty confident that  team would walk away with $ 20 000   but  do not remember the political adage    be never as far up as  think  be   when  relative anna step up to the plate    get exactly zero point    for example   no one in the survey though that throw up be a good answer for something a stomach do   the sass family do walk away with $ 5 per point and $ 910 be not too shabby  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# df_expanded['text_paras_lemma'] = df_expanded.text_paras_clean.map(spacy_lemmatization)\n",
    "df_expanded[['text_paras_clean','text_paras_lemma']].sample(2)\n",
    "\n",
    "# df_nlp_round1['text_lemma'] = df_nlp_round1.text_clean.map(spacy_lemmatization)\n",
    "# df_nlp_round1[['text','text_lemma']].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>A federal appeals court on Wednesday ordered a lower court to allow the case against former Nati...</td>\n",
       "      <td>federal appeals court wednesday ordered lower court allow case former national security adviser ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    text  \\\n",
       "187  A federal appeals court on Wednesday ordered a lower court to allow the case against former Nati...   \n",
       "\n",
       "                                                                                          text_stopwords  \n",
       "187  federal appeals court wednesday ordered lower court allow case former national security adviser ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "custom_words = ['ad','advertisment']\n",
    "\n",
    "df_expanded['text_paras_stopwords'] = df_expanded.text_paras_clean.map(lambda x: remove_stopwords(x, custom_words=custom_words))\n",
    "df_expanded[['text_paras_lemma','text_paras_stopwords']].sample(2)\n",
    "\n",
    "# df_nlp_round1['text_stopwords'] = df_nlp_round1.text_clean.map(remove_stopwords)\n",
    "# df_nlp_round1[['text','text_stopwords']].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp_round1['text_final'] = df_nlp_round1['text_stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100\n",
      "iteration: 2 of max_iter: 100\n",
      "iteration: 3 of max_iter: 100\n",
      "iteration: 4 of max_iter: 100\n",
      "iteration: 5 of max_iter: 100\n",
      "iteration: 6 of max_iter: 100\n",
      "iteration: 7 of max_iter: 100\n",
      "iteration: 8 of max_iter: 100\n",
      "iteration: 9 of max_iter: 100\n",
      "iteration: 10 of max_iter: 100\n",
      "iteration: 11 of max_iter: 100\n",
      "iteration: 12 of max_iter: 100\n",
      "iteration: 13 of max_iter: 100\n",
      "iteration: 14 of max_iter: 100\n",
      "iteration: 15 of max_iter: 100\n",
      "iteration: 16 of max_iter: 100\n",
      "iteration: 17 of max_iter: 100\n",
      "iteration: 18 of max_iter: 100\n",
      "iteration: 19 of max_iter: 100\n",
      "iteration: 20 of max_iter: 100\n",
      "iteration: 21 of max_iter: 100\n",
      "iteration: 22 of max_iter: 100\n",
      "iteration: 23 of max_iter: 100\n",
      "iteration: 24 of max_iter: 100\n",
      "iteration: 25 of max_iter: 100\n",
      "iteration: 26 of max_iter: 100\n",
      "iteration: 27 of max_iter: 100\n",
      "iteration: 28 of max_iter: 100\n",
      "iteration: 29 of max_iter: 100\n",
      "iteration: 30 of max_iter: 100\n",
      "iteration: 31 of max_iter: 100\n",
      "iteration: 32 of max_iter: 100\n",
      "iteration: 33 of max_iter: 100\n",
      "iteration: 34 of max_iter: 100\n",
      "iteration: 35 of max_iter: 100\n",
      "iteration: 36 of max_iter: 100\n",
      "iteration: 37 of max_iter: 100\n",
      "iteration: 38 of max_iter: 100\n",
      "iteration: 39 of max_iter: 100\n",
      "iteration: 40 of max_iter: 100\n",
      "iteration: 41 of max_iter: 100\n",
      "iteration: 42 of max_iter: 100\n",
      "iteration: 43 of max_iter: 100\n",
      "iteration: 44 of max_iter: 100\n",
      "iteration: 45 of max_iter: 100\n",
      "iteration: 46 of max_iter: 100\n",
      "iteration: 47 of max_iter: 100\n",
      "iteration: 48 of max_iter: 100\n",
      "iteration: 49 of max_iter: 100\n",
      "iteration: 50 of max_iter: 100\n",
      "iteration: 51 of max_iter: 100\n",
      "iteration: 52 of max_iter: 100\n",
      "iteration: 53 of max_iter: 100\n",
      "iteration: 54 of max_iter: 100\n",
      "iteration: 55 of max_iter: 100\n",
      "iteration: 56 of max_iter: 100\n",
      "iteration: 57 of max_iter: 100\n",
      "iteration: 58 of max_iter: 100\n",
      "iteration: 59 of max_iter: 100\n",
      "iteration: 60 of max_iter: 100\n",
      "iteration: 61 of max_iter: 100\n",
      "iteration: 62 of max_iter: 100\n",
      "iteration: 63 of max_iter: 100\n",
      "iteration: 64 of max_iter: 100\n",
      "iteration: 65 of max_iter: 100\n",
      "iteration: 66 of max_iter: 100\n",
      "iteration: 67 of max_iter: 100\n",
      "iteration: 68 of max_iter: 100\n",
      "iteration: 69 of max_iter: 100\n",
      "iteration: 70 of max_iter: 100\n",
      "iteration: 71 of max_iter: 100\n",
      "iteration: 72 of max_iter: 100\n",
      "iteration: 73 of max_iter: 100\n",
      "iteration: 74 of max_iter: 100\n",
      "iteration: 75 of max_iter: 100\n",
      "iteration: 76 of max_iter: 100\n",
      "iteration: 77 of max_iter: 100\n",
      "iteration: 78 of max_iter: 100\n",
      "iteration: 79 of max_iter: 100\n",
      "iteration: 80 of max_iter: 100\n",
      "iteration: 81 of max_iter: 100\n",
      "iteration: 82 of max_iter: 100\n",
      "iteration: 83 of max_iter: 100\n",
      "iteration: 84 of max_iter: 100\n",
      "iteration: 85 of max_iter: 100\n",
      "iteration: 86 of max_iter: 100\n",
      "iteration: 87 of max_iter: 100\n",
      "iteration: 88 of max_iter: 100\n",
      "iteration: 89 of max_iter: 100\n",
      "iteration: 90 of max_iter: 100\n",
      "iteration: 91 of max_iter: 100\n",
      "iteration: 92 of max_iter: 100\n",
      "iteration: 93 of max_iter: 100\n",
      "iteration: 94 of max_iter: 100\n",
      "iteration: 95 of max_iter: 100\n",
      "iteration: 96 of max_iter: 100\n",
      "iteration: 97 of max_iter: 100\n",
      "iteration: 98 of max_iter: 100\n",
      "iteration: 99 of max_iter: 100\n",
      "iteration: 100 of max_iter: 100\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'stop_words':'english','min_df': 10, 'max_df': 0.5, 'ngram_range':(1, 1),}\n",
    "\n",
    "tfidf = TfidfVectorizer(**params)\n",
    "review_word_matrix_tfidf = tfidf.fit_transform(df_nlp_round1['text_stopwords'])\n",
    "review_vocab_tfidf = tfidf.get_feature_names()\n",
    "\n",
    "lda_tfidf, score_tfidf, topic_matrix_tfidf, word_matrix_tfidf = lda_topic_modeling(review_word_matrix_tfidf, vocab = review_vocab_tfidf, n = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
